{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [],
   "source": [
    "from transformers import AutoProcessor, AutoModelForSpeechSeq2Seq\n",
    "from datasets import Dataset, Audio"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Load the transformer's model and the whisper processor\n",
    "In particular, we use a transformer and a Whisper processor that have 2 functions:\n",
    "- Pre-process the audio inputs (converting them to log-Mel spectrograms for the model)\n",
    "- Post-process the model outputs (converting them from tokens to text)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [
    {
     "data": {
      "text/plain": "Downloading (…)rocessor_config.json:   0%|          | 0.00/185k [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "83e97786d26541b1b5ee1b737d22c1b9"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Downloading (…)okenizer_config.json:   0%|          | 0.00/829 [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "0bc1e001ea95481f89d3aa5b6b5cd677"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Downloading (…)olve/main/vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "3e9a0d41c39542b49144ea2d4cc74de7"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Downloading (…)olve/main/merges.txt:   0%|          | 0.00/494k [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f7dbec3468bc427f907825c6e7441883"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Downloading (…)main/normalizer.json:   0%|          | 0.00/52.7k [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "5bba688865d240ebb707b3bc0133c063"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Downloading (…)in/added_tokens.json:   0%|          | 0.00/2.11k [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ec1dd9e0944d4b188ac23caf223b13df"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Downloading (…)cial_tokens_map.json:   0%|          | 0.00/2.06k [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "e189625825dc4ab9a75b99345959b76f"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Downloading (…)lve/main/config.json:   0%|          | 0.00/1.97k [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "dbcda737cba94d76bf319cd987c0554c"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Downloading (…)\"pytorch_model.bin\";:   0%|          | 0.00/6.17G [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "5bd25c42116b480395e32d81c1e03e33"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Downloading (…)neration_config.json:   0%|          | 0.00/3.49k [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "1bb5c4fd5fab47b99ff915e61b11646b"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "processor = AutoProcessor.from_pretrained(\"openai/whisper-large-v2\")\n",
    "model = AutoModelForSpeechSeq2Seq.from_pretrained(\"openai/whisper-large-v2\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Creation of an audio dataset from local files in recordings folder\n",
    "Despite normally a spectrogram works with a range of values between 40 kHz - 44 kHz, the model accepts only a sampling rate of 16 kHz"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [],
   "source": [
    "audio_dataset = Dataset.from_dict({\"audio\": [\"recordings/Prova.wav\", \"recordings/prova2.wav\"]}).cast_column(\"audio\", Audio(sampling_rate=16000))\n",
    "\n",
    "my_audio = audio_dataset[1]['audio']"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [
    {
     "data": {
      "text/plain": "{'path': 'recordings/prova2.wav',\n 'array': array([-0.00340922, -0.00526658, -0.00676686, ..., -0.00095332,\n        -0.00131988,  0.        ], dtype=float32),\n 'sampling_rate': 16000}"
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_audio"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Creation of the input features from the audio sample\n",
    "The input features are passed to the model, which will convert them into token ids.\n",
    "We're forcing the model to transcribe the audio to italian language.\n",
    "The decoder, then, will decode the token ids to text."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [],
   "source": [
    "# processor is a variable, but called as processor() indicates the magic method \"__call__\" is called\n",
    "input_features = processor(my_audio['array'], sampling_rate=my_audio['sampling_rate'], return_tensors='pt').input_features"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [],
   "source": [
    "model.config.forced_decoder_ids = processor.get_decoder_prompt_ids(language='italian', task='transcribe')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\claud\\PycharmProjects\\SpeechModel\\venv\\lib\\site-packages\\transformers\\generation\\utils.py:1273: UserWarning: Neither `max_length` nor `max_new_tokens` has been set, `max_length` will default to 448 (`generation_config.max_length`). Controlling `max_length` via the config is deprecated and `max_length` will be removed from the config in v5 of Transformers -- we recommend using `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "predicted_ids = model.generate(input_features)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [
    {
     "data": {
      "text/plain": "[\"<|startoftranscript|><|it|><|transcribe|><|notimestamps|> Le leggi sono le condizioni con le quali uomini indipendenti ed isolati si unirono in società, stanchi di vivere in un continuo stato di guerra e di godere una libertà resa inutile dall'incertezza di conservarla. Essine sacrificare una parte per goderne il restante con sicurezza e tranquillità.<|endoftext|>\"]"
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transcription = processor.batch_decode(predicted_ids, skip_special_tokens=False)\n",
    "transcription"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
